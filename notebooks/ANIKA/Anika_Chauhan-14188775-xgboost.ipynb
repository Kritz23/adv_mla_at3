{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72436c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python==3.9.13 (from versions: none)\n",
      "ERROR: No matching distribution found for python==3.9.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.0.1\n",
      "  Downloading pandas-2.0.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/10.6 MB 6.9 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.4/10.6 MB 6.2 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.8/10.6 MB 6.6 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.1/10.6 MB 5.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.3/10.6 MB 6.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.7/10.6 MB 6.4 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.0/10.6 MB 6.4 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.1/10.6 MB 6.3 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.1/10.6 MB 5.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.4/10.6 MB 5.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.7/10.6 MB 5.6 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.0/10.6 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.1/10.6 MB 5.7 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.3/10.6 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.5/10.6 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.7/10.6 MB 5.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.9/10.6 MB 5.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.2/10.6 MB 5.2 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 4.5/10.6 MB 5.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.6/10.6 MB 5.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.8/10.6 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 4.9/10.6 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.1/10.6 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.4/10.6 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.7/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 5.9/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.1/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 6.3/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 6.5/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.7/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 7.0/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.2/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.3/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.5/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 7.7/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.0/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.2/10.6 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.5/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.8/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.1/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.3/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.5/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.1/10.6 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.2/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.5/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.6/10.6 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.6/10.6 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas==2.0.1) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas==2.0.1) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas==2.0.1) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.0.1) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "Successfully installed pandas-2.0.1\n",
      "Collecting scikit-learn==1.3.1\n",
      "  Obtaining dependency information for scikit-learn==1.3.1 from https://files.pythonhosted.org/packages/f1/7d/2e562207176a5dcdad513085670674bb11ffaf37e1393eacb6d7fb502481/scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.1) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.1) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.1) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.1) (2.2.0)\n",
      "Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.2 MB 3.2 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.1/9.2 MB 1.7 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.2/9.2 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.3/9.2 MB 1.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/9.2 MB 1.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/9.2 MB 1.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.5/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.2 MB 858.2 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.7/9.2 MB 855.6 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.2 MB 950.8 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.9/9.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.4/9.2 MB 1.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.2 MB 1.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.8/9.2 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.0/9.2 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.2/9.2 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.4/9.2 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.8/9.2 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.0/9.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.2 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.2/9.2 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.4/9.2 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.6/9.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.9/9.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.1/9.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.4/9.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.6/9.2 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.8/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.1/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.3/9.2 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.4/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.6/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.7/9.2 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.9/9.2 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.1/9.2 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.2 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.8/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.4/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.8/9.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.5/9.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.2 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.2\n",
      "    Uninstalling scikit-learn-1.3.2:\n",
      "      Successfully uninstalled scikit-learn-1.3.2\n",
      "Successfully installed scikit-learn-1.3.1\n",
      "Collecting ipykernel==6.25.2\n",
      "  Obtaining dependency information for ipykernel==6.25.2 from https://files.pythonhosted.org/packages/94/e3/70fb6e6bdd42cb0586d6b6680713997d2a9dc46642aec207ca04d0df80b8/ipykernel-6.25.2-py3-none-any.whl.metadata\n",
      "  Downloading ipykernel-6.25.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (8.12.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (1.5.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipykernel==6.25.2) (5.7.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anika\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.25.2) (0.4.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel==6.25.2) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel==6.25.2) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.25.2) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.25.2) (305.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.25.2) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\anika\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel==6.25.2) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel==6.25.2) (1.16.0)\n",
      "Requirement already satisfied: executing in c:\\users\\anika\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.25.2) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\anika\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.25.2) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\anika\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.25.2) (0.2.2)\n",
      "Downloading ipykernel-6.25.2-py3-none-any.whl (154 kB)\n",
      "   ---------------------------------------- 0.0/154.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  153.6/154.2 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 154.2/154.2 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: ipykernel\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.19.2\n",
      "    Uninstalling ipykernel-6.19.2:\n",
      "      Successfully uninstalled ipykernel-6.19.2\n",
      "Successfully installed ipykernel-6.25.2\n",
      "Collecting matplotlib==3.8.0\n",
      "  Obtaining dependency information for matplotlib==3.8.0 from https://files.pythonhosted.org/packages/40/d9/c1784db9db0d484c8e5deeafbaac0d6ed66e165c6eb4a74fb43a5fa947d9/matplotlib-3.8.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.8.0-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib==3.8.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.0) (1.16.0)\n",
      "Downloading matplotlib-3.8.0-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/7.6 MB 901.1 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/7.6 MB 958.4 kB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/7.6 MB 1.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.4/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.4/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.5/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.5/7.6 MB 1.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.6/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.8/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.8/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.1/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.1/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.2/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.3/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.3/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.4/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.4/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.4/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.5/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.6/7.6 MB 1.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.7/7.6 MB 853.3 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.7/7.6 MB 853.3 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.8/7.6 MB 839.6 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.8/7.6 MB 843.3 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.9/7.6 MB 847.1 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 1.9/7.6 MB 846.5 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 1.9/7.6 MB 849.6 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 862.1 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 883.9 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.2/7.6 MB 882.0 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.2/7.6 MB 894.2 kB/s eta 0:00:07\n",
      "   ------------ --------------------------- 2.4/7.6 MB 932.0 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.4/7.6 MB 946.9 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.6/7.6 MB 984.8 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.6/7.6 MB 990.5 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.8/7.6 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.0/7.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.3/7.6 MB 892.4 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.6 MB 949.9 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.7/7.6 MB 991.2 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.0/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.2/7.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.6 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.7/7.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 4.9/7.6 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.1/7.6 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.4/7.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.6/7.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.8/7.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.0/7.6 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.3/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.5/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.7/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.9/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.1/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "Successfully installed matplotlib-3.8.0\n",
      "Collecting gdown==4.7.1\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gdown==4.7.1) (3.12.2)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gdown==4.7.1) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gdown==4.7.1) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gdown==4.7.1) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gdown==4.7.1) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown==4.7.1) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests[socks]->gdown==4.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests[socks]->gdown==4.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests[socks]->gdown==4.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests[socks]->gdown==4.7.1) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests[socks]->gdown==4.7.1) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anika\\anaconda3\\lib\\site-packages (from tqdm->gdown==4.7.1) (0.4.6)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.7.1\n",
      "Collecting isodate==0.6.1\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.7/41.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\anika\\anaconda3\\lib\\site-packages (from isodate==0.6.1) (1.16.0)\n",
      "Installing collected packages: isodate\n",
      "Successfully installed isodate-0.6.1\n",
      "Collecting shap==0.43.0\n",
      "  Obtaining dependency information for shap==0.43.0 from https://files.pythonhosted.org/packages/f5/fc/e81722d6bec4fcba46e46ef895eddaeab0027ac71e78fc35ef351fac5fe4/shap-0.43.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading shap-0.43.0-cp311-cp311-win_amd64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (1.3.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (23.0)\n",
      "Collecting slicer==0.0.7 (from shap==0.43.0)\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\anika\\anaconda3\\lib\\site-packages (from shap==0.43.0) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anika\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap==0.43.0) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from numba->shap==0.43.0) (0.40.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas->shap==0.43.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas->shap==0.43.0) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas->shap==0.43.0) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn->shap==0.43.0) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from scikit-learn->shap==0.43.0) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap==0.43.0) (1.16.0)\n",
      "Downloading shap-0.43.0-cp311-cp311-win_amd64.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.3 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 204.8/447.3 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 447.3/447.3 kB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.43.0 slicer-0.0.7\n",
      "Collecting wandb==0.16.0\n",
      "  Obtaining dependency information for wandb==0.16.0 from https://files.pythonhosted.org/packages/5c/81/1780aa129564b11709a6d7f0739257174f0a3a1b432ba804b3c6f00e0f88/wandb-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (8.0.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb==0.16.0)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/56/f7/d1d459caa0468217ab2638112c5ab31cde516aa3986f2ca292661644e6b8/sentry_sdk-1.34.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb==0.16.0)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (6.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (66.1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from wandb==0.16.0) (4.25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anika\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb==0.16.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb==0.16.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.0) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb==0.16.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb==0.16.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb==0.16.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb==0.16.0) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.0) (5.0.1)\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.9 kB ? eta -:--:--\n",
      "   -------------------------------------- - 235.5/243.9 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 243.9/243.9 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-1.34.0 wandb-0.16.0\n",
      "Collecting catboost==1.2.2\n",
      "  Obtaining dependency information for catboost==1.2.2 from https://files.pythonhosted.org/packages/e2/63/379617e3d982e8a66c9d66ebf4621d3357c7c18ad356473c335bffd5aba6/catboost-1.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading catboost-1.2.2-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (2.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\anika\\anaconda3\\lib\\site-packages (from catboost==1.2.2) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost==1.2.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost==1.2.2) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost==1.2.2) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from matplotlib->catboost==1.2.2) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from plotly->catboost==1.2.2) (8.2.2)\n",
      "Downloading catboost-1.2.2-cp311-cp311-win_amd64.whl (101.0 MB)\n",
      "   ---------------------------------------- 0.0/101.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/101.0 MB 4.1 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 0.4/101.0 MB 5.5 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 0.6/101.0 MB 4.4 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 0.9/101.0 MB 5.0 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 1.1/101.0 MB 4.7 MB/s eta 0:00:22\n",
      "    --------------------------------------- 1.4/101.0 MB 5.0 MB/s eta 0:00:20\n",
      "    --------------------------------------- 1.6/101.0 MB 5.0 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.1/101.0 MB 5.5 MB/s eta 0:00:19\n",
      "    --------------------------------------- 2.4/101.0 MB 5.6 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 2.7/101.0 MB 5.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 3.0/101.0 MB 5.8 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 3.2/101.0 MB 5.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 3.6/101.0 MB 5.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.8/101.0 MB 5.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 4.1/101.0 MB 5.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 4.3/101.0 MB 5.6 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 4.6/101.0 MB 5.6 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 4.8/101.0 MB 5.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 4.9/101.0 MB 5.5 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 5.1/101.0 MB 5.4 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 5.3/101.0 MB 5.3 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 5.4/101.0 MB 5.3 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.6/101.0 MB 5.2 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.8/101.0 MB 5.2 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 5.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.0/101.0 MB 2.6 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 6.1/101.0 MB 2.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 6.1/101.0 MB 2.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 6.1/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.1/101.0 MB 2.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 6.2/101.0 MB 2.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 6.4/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.5/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.7/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.9/101.0 MB 2.1 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 6.9/101.0 MB 2.1 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 7.1/101.0 MB 2.1 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 7.2/101.0 MB 2.2 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 7.5/101.0 MB 2.2 MB/s eta 0:00:43\n",
      "   --- ------------------------------------ 7.7/101.0 MB 2.2 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 8.0/101.0 MB 2.3 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 8.3/101.0 MB 2.3 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 8.6/101.0 MB 2.4 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 8.9/101.0 MB 2.4 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 9.1/101.0 MB 2.5 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 9.5/101.0 MB 2.5 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 9.8/101.0 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 10.1/101.0 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.4/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 10.5/101.0 MB 2.7 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.7/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 11.0/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 11.3/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 11.6/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 11.9/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 12.2/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 12.5/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 12.6/101.0 MB 2.7 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 12.6/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 13.0/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 13.3/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 13.6/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 13.9/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 14.2/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 14.5/101.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 14.8/101.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 15.1/101.0 MB 2.7 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 15.4/101.0 MB 2.7 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 15.6/101.0 MB 2.7 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 15.9/101.0 MB 2.7 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 16.3/101.0 MB 3.9 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 16.5/101.0 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.8/101.0 MB 4.3 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 17.0/101.0 MB 4.3 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 17.2/101.0 MB 5.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 17.5/101.0 MB 5.7 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 17.7/101.0 MB 5.7 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 18.0/101.0 MB 5.7 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 18.2/101.0 MB 5.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 18.4/101.0 MB 5.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 18.7/101.0 MB 5.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 18.9/101.0 MB 5.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 19.0/101.0 MB 5.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 19.2/101.0 MB 5.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.4/101.0 MB 5.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.7/101.0 MB 5.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.7/101.0 MB 5.3 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.9/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 20.2/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 20.3/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 20.6/101.0 MB 5.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 20.8/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.1/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.3/101.0 MB 5.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.3/101.0 MB 5.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.5/101.0 MB 5.0 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.7/101.0 MB 5.0 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 21.9/101.0 MB 4.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 22.1/101.0 MB 4.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 22.4/101.0 MB 4.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 22.6/101.0 MB 4.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 22.9/101.0 MB 5.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.0/101.0 MB 5.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.1/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.3/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.6/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 23.9/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.2/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.2/101.0 MB 4.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.4/101.0 MB 4.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 24.6/101.0 MB 4.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 24.7/101.0 MB 4.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 24.9/101.0 MB 4.6 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 25.1/101.0 MB 4.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.4/101.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.6/101.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 25.9/101.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 26.1/101.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 26.2/101.0 MB 4.4 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 26.4/101.0 MB 4.4 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 26.6/101.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.8/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.9/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.2/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.4/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.6/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.9/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.0/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.0/101.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.0/101.0 MB 4.1 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.1/101.0 MB 4.0 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.3/101.0 MB 4.0 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.4/101.0 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.6/101.0 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.7/101.0 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 28.8/101.0 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.0/101.0 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.1/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.3/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.5/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.6/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.8/101.0 MB 3.8 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.9/101.0 MB 3.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 30.0/101.0 MB 3.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 30.1/101.0 MB 3.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 30.2/101.0 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.4/101.0 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.5/101.0 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.6/101.0 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.7/101.0 MB 3.5 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.9/101.0 MB 3.5 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.0/101.0 MB 3.5 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 31.0/101.0 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.1/101.0 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.2/101.0 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.3/101.0 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.4/101.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.5/101.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.6/101.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.6/101.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.7/101.0 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.8/101.0 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 31.9/101.0 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.0/101.0 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.2/101.0 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.2/101.0 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.3/101.0 MB 3.1 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 32.5/101.0 MB 3.1 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 32.6/101.0 MB 3.1 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 32.7/101.0 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 32.8/101.0 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 32.9/101.0 MB 3.0 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.0/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.1/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.2/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.3/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.5/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.6/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.7/101.0 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 33.8/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.0/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.1/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.2/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.4/101.0 MB 2.8 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 34.6/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.7/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.9/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 35.1/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.4/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.6/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.8/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.0/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.2/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.4/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 36.8/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 36.9/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 36.9/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 37.0/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.2/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.3/101.0 MB 2.8 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.5/101.0 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.6/101.0 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 37.8/101.0 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 37.9/101.0 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 38.1/101.0 MB 2.7 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 38.3/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 38.5/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 38.7/101.0 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 38.9/101.0 MB 2.9 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 39.1/101.0 MB 2.9 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 39.3/101.0 MB 2.9 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 39.5/101.0 MB 2.9 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 39.8/101.0 MB 2.9 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 40.0/101.0 MB 3.0 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 40.3/101.0 MB 3.0 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 40.5/101.0 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 40.7/101.0 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 40.9/101.0 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 41.2/101.0 MB 3.2 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 41.4/101.0 MB 3.3 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 41.6/101.0 MB 3.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 41.9/101.0 MB 3.5 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 42.1/101.0 MB 3.5 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 42.4/101.0 MB 3.6 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 42.6/101.0 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 42.9/101.0 MB 3.8 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 43.1/101.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 43.3/101.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 43.6/101.0 MB 4.0 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 43.8/101.0 MB 4.1 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.1/101.0 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.3/101.0 MB 4.3 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.6/101.0 MB 4.3 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.8/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 45.1/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 45.3/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 45.5/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 45.8/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.0/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.1/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.4/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.6/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.7/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.9/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.1/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.3/101.0 MB 4.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 47.5/101.0 MB 4.6 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 47.6/101.0 MB 4.6 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 47.8/101.0 MB 4.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 47.8/101.0 MB 4.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 47.9/101.0 MB 4.5 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 48.0/101.0 MB 4.5 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 48.1/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.2/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/101.0 MB 4.4 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.4/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.5/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.7/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.9/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.0/101.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.2/101.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.3/101.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.4/101.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.6/101.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.7/101.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.8/101.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.0/101.0 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.0/101.0 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.2/101.0 MB 3.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.3/101.0 MB 3.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.5/101.0 MB 3.9 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 50.6/101.0 MB 3.8 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 50.7/101.0 MB 3.8 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 50.9/101.0 MB 3.8 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 50.9/101.0 MB 3.8 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.1/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.2/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.4/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.6/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.7/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.9/101.0 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.1/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.3/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.5/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.7/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 53.0/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 53.2/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 53.4/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 53.6/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 53.9/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.0/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.1/101.0 MB 3.6 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.4/101.0 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.6/101.0 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.8/101.0 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.9/101.0 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 55.1/101.0 MB 3.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 55.3/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 55.4/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 55.6/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 55.9/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 56.1/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 56.3/101.0 MB 3.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 56.5/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 56.7/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 56.9/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.0/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.1/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.1/101.0 MB 3.4 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.3/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 57.4/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 57.6/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 57.7/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 57.9/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 57.9/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 58.0/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 58.1/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 58.1/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.1/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.2/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.4/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.6/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.7/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 58.8/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.0/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.1/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.2/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.4/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.5/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.6/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.7/101.0 MB 2.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 59.8/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.0/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.1/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.2/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.3/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.4/101.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.5/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 60.6/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 60.7/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 60.8/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.0/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.1/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.2/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.4/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.5/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.6/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.7/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 61.9/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.0/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.1/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.2/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.3/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.4/101.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.5/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.6/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.7/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.8/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 62.9/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 2.0 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.6 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.6 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 63.0/101.0 MB 1.6 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 63.1/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 63.1/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.3/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.4/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.5/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.7/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.8/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 63.9/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.0/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.2/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.3/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.5/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.6/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.8/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 64.9/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 65.1/101.0 MB 1.5 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 65.2/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 65.4/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 65.5/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 65.6/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 65.8/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.0/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.2/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.3/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.5/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.6/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.7/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.8/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 66.9/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.0/101.0 MB 1.5 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.1/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.2/101.0 MB 1.4 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 67.3/101.0 MB 1.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 67.3/101.0 MB 1.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 67.3/101.0 MB 1.3 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 67.3/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.3/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.4/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.5/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.6/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.7/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.8/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 67.9/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 68.0/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 68.1/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.2/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.3/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.4/101.0 MB 1.4 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.5/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.3 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 68.6/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.7/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.7/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.8/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 68.9/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 69.0/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 69.1/101.0 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 69.3/101.0 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 69.5/101.0 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 69.7/101.0 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 69.8/101.0 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 70.1/101.0 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 70.3/101.0 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 70.5/101.0 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 70.7/101.0 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 70.8/101.0 MB 1.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 71.0/101.0 MB 1.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 71.2/101.0 MB 1.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 71.4/101.0 MB 1.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 71.7/101.0 MB 1.2 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 72.0/101.0 MB 1.2 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 72.2/101.0 MB 1.2 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 72.4/101.0 MB 1.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 72.7/101.0 MB 1.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 72.9/101.0 MB 1.3 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 73.2/101.0 MB 1.4 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 73.4/101.0 MB 1.8 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 73.6/101.0 MB 1.8 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 73.8/101.0 MB 1.8 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 74.0/101.0 MB 1.9 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 74.3/101.0 MB 1.9 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 74.5/101.0 MB 1.9 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 74.7/101.0 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.0/101.0 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.3/101.0 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.5/101.0 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 75.8/101.0 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.0/101.0 MB 1.9 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 76.3/101.0 MB 1.9 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 76.5/101.0 MB 2.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 76.8/101.0 MB 2.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 77.0/101.0 MB 2.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 77.2/101.0 MB 2.0 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 77.4/101.0 MB 2.0 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 77.7/101.0 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 78.0/101.0 MB 2.9 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 78.2/101.0 MB 2.9 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 78.5/101.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 78.7/101.0 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 79.1/101.0 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 79.6/101.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 79.9/101.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.2/101.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.4/101.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.7/101.0 MB 5.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 80.9/101.0 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 81.2/101.0 MB 5.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 81.5/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 81.8/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 82.1/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 82.3/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 82.6/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 82.9/101.0 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 83.2/101.0 MB 5.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 83.5/101.0 MB 5.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 83.8/101.0 MB 5.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.0/101.0 MB 5.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.4/101.0 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.7/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.0/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.3/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.5/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 85.8/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.1/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.4/101.0 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.6/101.0 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 86.9/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.0/101.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.0/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.2/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.5/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.7/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 87.9/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 88.2/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.5/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.7/101.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.9/101.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.1/101.0 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.4/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.7/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.0/101.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.3/101.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.6/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.8/101.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.0/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.3/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.6/101.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 91.8/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.0/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.0/101.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.3/101.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.5/101.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.6/101.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.8/101.0 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.9/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.0/101.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.0/101.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.0/101.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.1/101.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.2/101.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 93.2/101.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 93.2/101.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 93.2/101.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 93.3/101.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 93.4/101.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.5/101.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.6/101.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.7/101.0 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.8/101.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.8/101.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.9/101.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.0/101.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.1/101.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.2/101.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.4/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.5/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.6/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.6/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.8/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 94.9/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.0/101.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.1/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.1/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.2/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.3/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.4/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.5/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.5/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.0 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.6/101.0 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.6/101.0 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.7/101.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.8/101.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.9/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 96.0/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.1/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.2/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.4/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.6/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.8/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.9/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.0/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.2/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.2/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.4/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.6/101.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.8/101.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.9/101.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.2/101.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.3/101.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.4/101.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.5/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  98.6/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.2/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.3/101.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.5/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.8/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.8/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.0/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.1/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.2/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.3/101.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.4/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.4/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.5/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.6/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.8/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.8/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.0 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.0/101.0 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: catboost\n",
      "  Attempting uninstall: catboost\n",
      "    Found existing installation: catboost 1.2\n",
      "    Uninstalling catboost-1.2:\n",
      "      Successfully uninstalled catboost-1.2\n",
      "Successfully installed catboost-1.2.2\n",
      "Requirement already satisfied: streamlit==1.28.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (1.28.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (5.1.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (6.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (2.0.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (9.4.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (4.25.0)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (13.6.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (4.7.1)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from streamlit==1.28.1) (2.1.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.28.1) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.28.1) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\anika\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.28.1) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anika\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit==1.28.1) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.28.1) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit==1.28.1) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit==1.28.1) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit==1.28.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit==1.28.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.28.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.28.1) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.28.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.28.1) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.28.1) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.28.1) (2.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.28.1) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.28.1) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.28.1) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.28.1) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\anika\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.28.1) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "#required dependencies\n",
    "!pip install python==3.9.13\n",
    "!pip install pandas==2.0.1\n",
    "!pip install scikit-learn==1.3.1\n",
    "!pip install ipykernel==6.25.2\n",
    "!pip install matplotlib==3.8.0\n",
    "!pip install gdown==4.7.1\n",
    "!pip install isodate==0.6.1\n",
    "!pip install shap==0.43.0\n",
    "!pip install wandb==0.16.0\n",
    "!pip install catboost==1.2.2\n",
    "!pip install streamlit==1.28.1\n",
    "!pip install xgboost==1.7.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading data from zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46f4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../../data/processed/data_cleaned.pkl.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af97bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>segmentsDepartureTimeEpochSeconds_Leg1</th>\n",
       "      <th>...</th>\n",
       "      <th>segmentsDurationInSeconds_Leg4</th>\n",
       "      <th>segmentsDistance_Leg1</th>\n",
       "      <th>segmentsDistance_Leg2</th>\n",
       "      <th>segmentsDistance_Leg3</th>\n",
       "      <th>segmentsDistance_Leg4</th>\n",
       "      <th>segmentsCabinCode_Leg1</th>\n",
       "      <th>segmentsCabinCode_Leg2</th>\n",
       "      <th>segmentsCabinCode_Leg3</th>\n",
       "      <th>segmentsCabinCode_Leg4</th>\n",
       "      <th>traveltime_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9738944</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>MIA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>187.199997</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>1.652179e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806467</th>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DEN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>398.589996</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.654549e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734482</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>147.600006</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>1.651574e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651284</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>DTW</td>\n",
       "      <td>PHL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>217.610001</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1.652810e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348808</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ORD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>205.600006</td>\n",
       "      <td>862.0</td>\n",
       "      <td>1.655465e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667274</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>BOS</td>\n",
       "      <td>OAK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>728.599976</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>1.652443e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258352</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>CLT</td>\n",
       "      <td>DFW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>614.099976</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1.653255e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568777</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SFO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>170.600006</td>\n",
       "      <td>351.0</td>\n",
       "      <td>1.651273e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969572</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>SFO</td>\n",
       "      <td>IAD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>567.210022</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>1.654098e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574260</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PHL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>301.600006</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1.652011e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7733374</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SFO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>178.600006</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1.652713e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035210</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>PHL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>307.600006</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>1.655824e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10112302</th>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>MIA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>313.600006</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>1.655482e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707457</th>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>CLT</td>\n",
       "      <td>ORD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>205.110001</td>\n",
       "      <td>745.0</td>\n",
       "      <td>1.657965e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911962</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>CLT</td>\n",
       "      <td>DFW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>397.100006</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1.651489e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610351</th>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>301.609985</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1.653420e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964086</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>228.600006</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.655547e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325043</th>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>261.589996</td>\n",
       "      <td>591.0</td>\n",
       "      <td>1.652782e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564653</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CLT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>498.600006</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>1.653749e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2458.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891360</th>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>DTW</td>\n",
       "      <td>SFO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>604.609985</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>1.655633e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>coach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.816667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          searchDate  flightDate startingAirport destinationAirport  \\\n",
       "9738944   2022-04-25  2022-05-10             MIA                DTW   \n",
       "5806467   2022-05-18  2022-06-06             EWR                DEN   \n",
       "9734482   2022-04-25  2022-05-03             MIA                DEN   \n",
       "4651284   2022-04-27  2022-05-17             DTW                PHL   \n",
       "1348808   2022-04-30  2022-06-17             BOS                ORD   \n",
       "1667274   2022-05-09  2022-05-13             BOS                OAK   \n",
       "2258352   2022-04-30  2022-05-22             CLT                DFW   \n",
       "7568777   2022-04-27  2022-04-29             LAX                SFO   \n",
       "12969572  2022-04-29  2022-06-01             SFO                IAD   \n",
       "3574260   2022-04-19  2022-05-08             DFW                PHL   \n",
       "7733374   2022-04-30  2022-05-16             LAX                SFO   \n",
       "12035210  2022-04-25  2022-06-21             PHL                DFW   \n",
       "10112302  2022-05-06  2022-06-17             MIA                DFW   \n",
       "2707457   2022-05-18  2022-07-16             CLT                ORD   \n",
       "1911962   2022-04-18  2022-05-02             CLT                DFW   \n",
       "610351    2022-05-06  2022-05-24             ATL                MIA   \n",
       "8964086   2022-04-30  2022-06-18             LGA                DTW   \n",
       "5325043   2022-04-24  2022-05-17             EWR                IAD   \n",
       "7564653   2022-04-26  2022-05-28             LAX                CLT   \n",
       "4891360   2022-05-05  2022-06-19             DTW                SFO   \n",
       "\n",
       "          isBasicEconomy  isRefundable  isNonStop   totalFare  \\\n",
       "9738944            False         False      False  187.199997   \n",
       "5806467            False         False      False  398.589996   \n",
       "9734482            False         False      False  147.600006   \n",
       "4651284            False         False      False  217.610001   \n",
       "1348808            False         False       True  205.600006   \n",
       "1667274            False         False      False  728.599976   \n",
       "2258352            False         False      False  614.099976   \n",
       "7568777            False         False       True  170.600006   \n",
       "12969572           False         False      False  567.210022   \n",
       "3574260            False         False      False  301.600006   \n",
       "7733374            False         False       True  178.600006   \n",
       "12035210           False         False      False  307.600006   \n",
       "10112302           False         False      False  313.600006   \n",
       "2707457            False         False      False  205.110001   \n",
       "1911962            False         False      False  397.100006   \n",
       "610351             False         False      False  301.609985   \n",
       "8964086            False         False       True  228.600006   \n",
       "5325043            False         False      False  261.589996   \n",
       "7564653            False         False      False  498.600006   \n",
       "4891360            False         False      False  604.609985   \n",
       "\n",
       "          totalTravelDistance  segmentsDepartureTimeEpochSeconds_Leg1  ...  \\\n",
       "9738944                1589.0                            1.652179e+09  ...   \n",
       "5806467                1627.0                            1.654549e+09  ...   \n",
       "9734482                1834.0                            1.651574e+09  ...   \n",
       "4651284                 912.0                            1.652810e+09  ...   \n",
       "1348808                 862.0                            1.655465e+09  ...   \n",
       "1667274                2944.0                            1.652443e+09  ...   \n",
       "2258352                1391.0                            1.653255e+09  ...   \n",
       "7568777                 351.0                            1.651273e+09  ...   \n",
       "12969572               2991.0                            1.654098e+09  ...   \n",
       "3574260                1304.0                            1.652011e+09  ...   \n",
       "7733374                 339.0                            1.652713e+09  ...   \n",
       "12035210               1392.0                            1.655824e+09  ...   \n",
       "10112302               1321.0                            1.655482e+09  ...   \n",
       "2707457                 745.0                            1.657965e+09  ...   \n",
       "1911962                1149.0                            1.651489e+09  ...   \n",
       "610351                 1866.0                            1.653420e+09  ...   \n",
       "8964086                 485.0                            1.655547e+09  ...   \n",
       "5325043                 591.0                            1.652782e+09  ...   \n",
       "7564653                3003.0                            1.653749e+09  ...   \n",
       "4891360                2087.0                            1.655633e+09  ...   \n",
       "\n",
       "          segmentsDurationInSeconds_Leg4  segmentsDistance_Leg1  \\\n",
       "9738944                              0.0                 1104.0   \n",
       "5806467                              0.0                  485.0   \n",
       "9734482                              0.0                  958.0   \n",
       "4651284                              0.0                  240.0   \n",
       "1348808                              0.0                  862.0   \n",
       "1667274                              0.0                 2606.0   \n",
       "2258352                              0.0                  592.0   \n",
       "7568777                              0.0                  351.0   \n",
       "12969572                             0.0                  679.0   \n",
       "3574260                              0.0                 1177.0   \n",
       "7733374                              0.0                  339.0   \n",
       "12035210                             0.0                  667.0   \n",
       "10112302                             0.0                  596.0   \n",
       "2707457                              0.0                  505.0   \n",
       "1911962                              0.0                  916.0   \n",
       "610351                               0.0                  762.0   \n",
       "8964086                              0.0                  485.0   \n",
       "5325043                              0.0                  185.0   \n",
       "7564653                              0.0                 2458.0   \n",
       "4891360                              0.0                  240.0   \n",
       "\n",
       "          segmentsDistance_Leg2 segmentsDistance_Leg3 segmentsDistance_Leg4  \\\n",
       "9738944                   485.0                   0.0                   0.0   \n",
       "5806467                  1142.0                   0.0                   0.0   \n",
       "9734482                   876.0                   0.0                   0.0   \n",
       "4651284                   672.0                   0.0                   0.0   \n",
       "1348808                     0.0                   0.0                   0.0   \n",
       "1667274                   338.0                   0.0                   0.0   \n",
       "2258352                   799.0                   0.0                   0.0   \n",
       "7568777                     0.0                   0.0                   0.0   \n",
       "12969572                 2312.0                   0.0                   0.0   \n",
       "3574260                   127.0                   0.0                   0.0   \n",
       "7733374                     0.0                   0.0                   0.0   \n",
       "12035210                  725.0                   0.0                   0.0   \n",
       "10112302                  725.0                   0.0                   0.0   \n",
       "2707457                   240.0                   0.0                   0.0   \n",
       "1911962                   233.0                   0.0                   0.0   \n",
       "610351                   1104.0                   0.0                   0.0   \n",
       "8964086                     0.0                   0.0                   0.0   \n",
       "5325043                   406.0                   0.0                   0.0   \n",
       "7564653                   545.0                   0.0                   0.0   \n",
       "4891360                  1847.0                   0.0                   0.0   \n",
       "\n",
       "         segmentsCabinCode_Leg1 segmentsCabinCode_Leg2  \\\n",
       "9738944                   coach                  coach   \n",
       "5806467                   coach                  coach   \n",
       "9734482                   coach                  coach   \n",
       "4651284                   coach                  coach   \n",
       "1348808                   coach                      0   \n",
       "1667274                   coach                  coach   \n",
       "2258352                   coach                  coach   \n",
       "7568777                   coach                      0   \n",
       "12969572                  coach                  coach   \n",
       "3574260                   coach                  coach   \n",
       "7733374                   coach                      0   \n",
       "12035210                  coach                  coach   \n",
       "10112302                  coach                  coach   \n",
       "2707457                   coach                  coach   \n",
       "1911962                   coach                  coach   \n",
       "610351                    coach                  coach   \n",
       "8964086                   coach                      0   \n",
       "5325043                   coach                  coach   \n",
       "7564653                   coach                  coach   \n",
       "4891360                   coach                  coach   \n",
       "\n",
       "          segmentsCabinCode_Leg3  segmentsCabinCode_Leg4  traveltime_hours  \n",
       "9738944                        0                       0         11.216667  \n",
       "5806467                        0                       0          8.100000  \n",
       "9734482                        0                       0          7.083333  \n",
       "4651284                        0                       0          7.683333  \n",
       "1348808                        0                       0          2.833333  \n",
       "1667274                        0                       0         10.216667  \n",
       "2258352                        0                       0          6.483333  \n",
       "7568777                        0                       0          1.550000  \n",
       "12969572                       0                       0         12.183333  \n",
       "3574260                        0                       0          4.650000  \n",
       "7733374                        0                       0          1.483333  \n",
       "12035210                       0                       0          6.066667  \n",
       "10112302                       0                       0          4.966667  \n",
       "2707457                        0                       0          4.366667  \n",
       "1911962                        0                       0          7.416667  \n",
       "610351                         0                       0          8.433333  \n",
       "8964086                        0                       0          1.833333  \n",
       "5325043                        0                       0          5.766667  \n",
       "7564653                        0                       0         11.500000  \n",
       "4891360                        0                       0          6.816667  \n",
       "\n",
       "[20 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af01d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13519999, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8004faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13519999 entries, 0 to 13519998\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                  Dtype   \n",
      "---  ------                                  -----   \n",
      " 0   searchDate                              object  \n",
      " 1   flightDate                              object  \n",
      " 2   startingAirport                         category\n",
      " 3   destinationAirport                      category\n",
      " 4   isBasicEconomy                          bool    \n",
      " 5   isRefundable                            bool    \n",
      " 6   isNonStop                               bool    \n",
      " 7   totalFare                               float32 \n",
      " 8   totalTravelDistance                     float32 \n",
      " 9   segmentsDepartureTimeEpochSeconds_Leg1  float32 \n",
      " 10  segmentsDepartureTimeEpochSeconds_Leg2  float32 \n",
      " 11  segmentsDepartureTimeEpochSeconds_Leg3  float32 \n",
      " 12  segmentsDepartureTimeEpochSeconds_Leg4  float32 \n",
      " 13  segmentsDepartureTimeRaw_Leg1           object  \n",
      " 14  segmentsDepartureTimeRaw_Leg2           object  \n",
      " 15  segmentsDepartureTimeRaw_Leg3           object  \n",
      " 16  segmentsDepartureTimeRaw_Leg4           object  \n",
      " 17  segmentsArrivalTimeEpochSeconds_Leg1    float32 \n",
      " 18  segmentsArrivalTimeEpochSeconds_Leg2    float32 \n",
      " 19  segmentsArrivalTimeEpochSeconds_Leg3    float32 \n",
      " 20  segmentsArrivalTimeEpochSeconds_Leg4    float32 \n",
      " 21  segmentsArrivalTimeRaw_Leg1             object  \n",
      " 22  segmentsArrivalTimeRaw_Leg2             object  \n",
      " 23  segmentsArrivalTimeRaw_Leg3             object  \n",
      " 24  segmentsArrivalTimeRaw_Leg4             object  \n",
      " 25  segmentsArrivalAirportCode_Leg1         category\n",
      " 26  segmentsArrivalAirportCode_Leg2         category\n",
      " 27  segmentsArrivalAirportCode_Leg3         category\n",
      " 28  segmentsArrivalAirportCode_Leg4         category\n",
      " 29  segmentsDepartureAirportCode_Leg1       category\n",
      " 30  segmentsDepartureAirportCode_Leg2       category\n",
      " 31  segmentsDepartureAirportCode_Leg3       category\n",
      " 32  segmentsDepartureAirportCode_Leg4       category\n",
      " 33  segmentsAirlineName_Leg1                category\n",
      " 34  segmentsAirlineName_Leg2                category\n",
      " 35  segmentsAirlineName_Leg3                category\n",
      " 36  segmentsAirlineName_Leg4                category\n",
      " 37  segmentsAirlineCode_Leg1                category\n",
      " 38  segmentsAirlineCode_Leg2                category\n",
      " 39  segmentsAirlineCode_Leg3                category\n",
      " 40  segmentsAirlineCode_Leg4                category\n",
      " 41  segmentsEquipmentDescription_Leg1       category\n",
      " 42  segmentsEquipmentDescription_Leg2       category\n",
      " 43  segmentsEquipmentDescription_Leg3       category\n",
      " 44  segmentsEquipmentDescription_Leg4       category\n",
      " 45  segmentsDurationInSeconds_Leg1          float32 \n",
      " 46  segmentsDurationInSeconds_Leg2          float32 \n",
      " 47  segmentsDurationInSeconds_Leg3          float32 \n",
      " 48  segmentsDurationInSeconds_Leg4          float32 \n",
      " 49  segmentsDistance_Leg1                   float32 \n",
      " 50  segmentsDistance_Leg2                   float32 \n",
      " 51  segmentsDistance_Leg3                   float32 \n",
      " 52  segmentsDistance_Leg4                   float32 \n",
      " 53  segmentsCabinCode_Leg1                  category\n",
      " 54  segmentsCabinCode_Leg2                  category\n",
      " 55  segmentsCabinCode_Leg3                  category\n",
      " 56  segmentsCabinCode_Leg4                  category\n",
      " 57  traveltime_hours                        float64 \n",
      "dtypes: bool(3), category(26), float32(18), float64(1), object(10)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36881e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['flightDate'] = pd.to_datetime(data['flightDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breaking down date into month, day, day of week, week of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ccadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['flightMonth'] = data['flightDate'].dt.month\n",
    "data['flightDay'] = data['flightDate'].dt.day\n",
    "data['flightDayOfWeek'] = data['flightDate'].dt.dayofweek\n",
    "data['flightWeekOfYear'] = data['flightDate'].dt.isocalendar().week\n",
    "data['flightIsWeekend'] = data['flightDate'].dt.dayofweek >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92646123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cabin_type'] = data['segmentsCabinCode_Leg1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243fc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['traveltime_hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff1f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['totalTravelDistance'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f46d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['segmentsDepartureTimeRaw_Leg1'] = pd.to_datetime(data['segmentsDepartureTimeRaw_Leg1'], utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories for time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c79a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a new feature 'departure_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4652a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['departure_time'] = data['segmentsDepartureTimeRaw_Leg1'].dt.hour.apply(categorize_time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce577f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12285686 entries, 0 to 13519918\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                  Dtype              \n",
      "---  ------                                  -----              \n",
      " 0   searchDate                              object             \n",
      " 1   flightDate                              datetime64[ns]     \n",
      " 2   startingAirport                         category           \n",
      " 3   destinationAirport                      category           \n",
      " 4   isBasicEconomy                          bool               \n",
      " 5   isRefundable                            bool               \n",
      " 6   isNonStop                               bool               \n",
      " 7   totalFare                               float32            \n",
      " 8   totalTravelDistance                     float32            \n",
      " 9   segmentsDepartureTimeEpochSeconds_Leg1  float32            \n",
      " 10  segmentsDepartureTimeEpochSeconds_Leg2  float32            \n",
      " 11  segmentsDepartureTimeEpochSeconds_Leg3  float32            \n",
      " 12  segmentsDepartureTimeEpochSeconds_Leg4  float32            \n",
      " 13  segmentsDepartureTimeRaw_Leg1           datetime64[ns, UTC]\n",
      " 14  segmentsDepartureTimeRaw_Leg2           object             \n",
      " 15  segmentsDepartureTimeRaw_Leg3           object             \n",
      " 16  segmentsDepartureTimeRaw_Leg4           object             \n",
      " 17  segmentsArrivalTimeEpochSeconds_Leg1    float32            \n",
      " 18  segmentsArrivalTimeEpochSeconds_Leg2    float32            \n",
      " 19  segmentsArrivalTimeEpochSeconds_Leg3    float32            \n",
      " 20  segmentsArrivalTimeEpochSeconds_Leg4    float32            \n",
      " 21  segmentsArrivalTimeRaw_Leg1             object             \n",
      " 22  segmentsArrivalTimeRaw_Leg2             object             \n",
      " 23  segmentsArrivalTimeRaw_Leg3             object             \n",
      " 24  segmentsArrivalTimeRaw_Leg4             object             \n",
      " 25  segmentsArrivalAirportCode_Leg1         category           \n",
      " 26  segmentsArrivalAirportCode_Leg2         category           \n",
      " 27  segmentsArrivalAirportCode_Leg3         category           \n",
      " 28  segmentsArrivalAirportCode_Leg4         category           \n",
      " 29  segmentsDepartureAirportCode_Leg1       category           \n",
      " 30  segmentsDepartureAirportCode_Leg2       category           \n",
      " 31  segmentsDepartureAirportCode_Leg3       category           \n",
      " 32  segmentsDepartureAirportCode_Leg4       category           \n",
      " 33  segmentsAirlineName_Leg1                category           \n",
      " 34  segmentsAirlineName_Leg2                category           \n",
      " 35  segmentsAirlineName_Leg3                category           \n",
      " 36  segmentsAirlineName_Leg4                category           \n",
      " 37  segmentsAirlineCode_Leg1                category           \n",
      " 38  segmentsAirlineCode_Leg2                category           \n",
      " 39  segmentsAirlineCode_Leg3                category           \n",
      " 40  segmentsAirlineCode_Leg4                category           \n",
      " 41  segmentsEquipmentDescription_Leg1       category           \n",
      " 42  segmentsEquipmentDescription_Leg2       category           \n",
      " 43  segmentsEquipmentDescription_Leg3       category           \n",
      " 44  segmentsEquipmentDescription_Leg4       category           \n",
      " 45  segmentsDurationInSeconds_Leg1          float32            \n",
      " 46  segmentsDurationInSeconds_Leg2          float32            \n",
      " 47  segmentsDurationInSeconds_Leg3          float32            \n",
      " 48  segmentsDurationInSeconds_Leg4          float32            \n",
      " 49  segmentsDistance_Leg1                   float32            \n",
      " 50  segmentsDistance_Leg2                   float32            \n",
      " 51  segmentsDistance_Leg3                   float32            \n",
      " 52  segmentsDistance_Leg4                   float32            \n",
      " 53  segmentsCabinCode_Leg1                  category           \n",
      " 54  segmentsCabinCode_Leg2                  category           \n",
      " 55  segmentsCabinCode_Leg3                  category           \n",
      " 56  segmentsCabinCode_Leg4                  category           \n",
      " 57  traveltime_hours                        float64            \n",
      " 58  flightMonth                             int64              \n",
      " 59  flightDay                               int64              \n",
      " 60  flightDayOfWeek                         int64              \n",
      " 61  flightWeekOfYear                        UInt32             \n",
      " 62  flightIsWeekend                         bool               \n",
      " 63  cabin_type                              category           \n",
      " 64  departure_time                          object             \n",
      "dtypes: UInt32(1), bool(4), category(27), datetime64[ns, UTC](1), datetime64[ns](1), float32(18), float64(1), int64(3), object(9)\n",
      "memory usage: 2.7+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a dataset with only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a686fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    'startingAirport',\n",
    "    'destinationAirport',\n",
    "    'totalFare',\n",
    "    'totalTravelDistance',\n",
    "    'traveltime_hours',\n",
    "    'flightMonth',\n",
    "    'flightDay',\n",
    "    'flightDayOfWeek',\n",
    "    'flightWeekOfYear',\n",
    "    'flightIsWeekend',\n",
    "    'cabin_type',\n",
    "    'departure_time'\n",
    "]\n",
    "\n",
    "final_data = data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86217950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09d856a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop('totalFare', axis=1)\n",
    "y = final_data['totalFare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78096b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['startingAirport', 'destinationAirport', 'cabin_type', 'departure_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0201793",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in label_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7d3a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_, y_train, y_ = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_, y_, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d83441",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "dummy model based on the mean value of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88779133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error of the baseline model: 209.85630798339844\n"
     ]
    }
   ],
   "source": [
    "mean_total_fare = y_train.mean()\n",
    "\n",
    "baseline_predictions = [mean_total_fare] * len(X_test)\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, baseline_predictions))\n",
    "print(f\"Root Mean Squared Error of the baseline model: {rmse_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling and encoding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "678fe5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=['category', 'object', 'bool']).columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_val_encoded = encoder.transform(X_val[categorical_cols])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78803cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.concatenate([X_train_encoded.toarray(), X_train.drop(categorical_cols, axis=1).values], axis=1)\n",
    "X_val_processed = np.concatenate([X_val_encoded.toarray(), X_val.drop(categorical_cols, axis=1).values], axis=1)\n",
    "X_test_processed = np.concatenate([X_test_encoded.toarray(), X_test.drop(categorical_cols, axis=1).values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dc0067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
    "X_val_scaled = scaler.transform(X_val_processed)\n",
    "X_test_scaled = scaler.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7d21cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8599980, 11), (1842853, 11), (1842853, 11))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining path to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54e2e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e43c5",
   "metadata": {},
   "source": [
    "### exp 1 XGBOOST with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dda9c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_default_model = XGBRegressor()\n",
    "xgb_default_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2342b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_xgb_default = xgb_default_model.predict(X_train_scaled)\n",
    "test_predictions_xgb_default = xgb_default_model.predict(X_test_scaled)\n",
    "val_predictions_xgb_default = xgb_default_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f300314",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_xgb_default = mean_squared_error(y_train, train_predictions_xgb_default, squared=False)\n",
    "test_rmse_xgb_default = mean_squared_error(y_test, test_predictions_xgb_default, squared=False)\n",
    "val_rmse_xgb_default = mean_squared_error(y_test, val_predictions_xgb_default, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a94e54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 115.89431762695312\n",
      "Test RMSE: 115.97388458251953\n",
      "Val RMSE: 268.9998779296875\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training RMSE: {train_rmse_xgb_default}\")\n",
    "print(f\"Test RMSE: {test_rmse_xgb_default}\")\n",
    "print(f\"Val RMSE: {val_rmse_xgb_default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0e8804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/ANIKA/xgb_default_model.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_default_model, '../../models/ANIKA/xgb_default_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3707ac67",
   "metadata": {},
   "source": [
    "### exp 2 XGBOOST with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7068a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned_model = XGBRegressor()\n",
    "param_grid_xgb_tuned = {\n",
    "    'n_estimators': [150],  \n",
    "    'max_depth': [3, 4, 5],          \n",
    "    'learning_rate': [0.01, 0.1, 0.2]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70b959e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5], &#x27;n_estimators&#x27;: [150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5], &#x27;n_estimators&#x27;: [150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5], 'n_estimators': [150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search__xgb_tuned = GridSearchCV(xgb_tuned_model, param_grid_xgb_tuned, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search__xgb_tuned.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8e43486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "best_params__xgb_tuned = grid_search__xgb_tuned.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params__xgb_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cb070c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tuned_model = XGBRegressor(**best_params__xgb_tuned)\n",
    "xgb_tuned_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62330cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_xgb_tuned = xgb_tuned_model.predict(X_train_scaled)\n",
    "test_predictions_xgb_tuned = xgb_tuned_model.predict(X_test_scaled)\n",
    "val_predictions_xgb_tuned = xgb_tuned_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "159644da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_xgb_tuned = mean_squared_error(y_train, train_predictions_xgb_tuned, squared=False)\n",
    "test_rmse_xgb_tuned = mean_squared_error(y_test, test_predictions_xgb_tuned, squared=False)\n",
    "val_rmse_xgb_tuned = mean_squared_error(y_val, val_predictions_xgb_tuned, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57c59431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 120.94856262207031\n",
      "Test RMSE: 120.98704528808594\n",
      "Val RMSE: 121.26666259765625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training RMSE: {train_rmse_xgb_tuned}\")\n",
    "print(f\"Test RMSE: {test_rmse_xgb_tuned}\")\n",
    "print(f\"Val RMSE: {val_rmse_xgb_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a129838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/ANIKA/xgb_tuned_model.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_tuned_model, '../../models/ANIKA/xgb_tuned_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f869d",
   "metadata": {},
   "source": [
    "### exp 3 LightGBM with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4471334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 8599980, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.028191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb_default_model = LGBMRegressor()\n",
    "lgb_default_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5940a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lgb_dafault = lgb_default_model.predict(X_train_scaled)\n",
    "test_predictions_lgb_dafault = lgb_default_model.predict(X_test_scaled)\n",
    "val_predictions_lgb_dafault = lgb_default_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29c45f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_lgb_dafault = mean_squared_error(y_train, train_predictions_lgb_dafault, squared=False)\n",
    "test_rmse_lgb_dafault = mean_squared_error(y_test, test_predictions_lgb_dafault, squared=False)\n",
    "val_rmse_lgb_dafault = mean_squared_error(y_val, val_predictions_lgb_dafault, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14ce2d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 126.71615858634355\n",
      "Test RMSE: 126.6701864455369\n",
      "Val RMSE: 126.99565346390084\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training RMSE: {train_rmse_lgb_dafault}\")\n",
    "print(f\"Test RMSE: {test_rmse_lgb_dafault}\")\n",
    "print(f\"Val RMSE: {val_rmse_lgb_dafault}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "735977d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/ANIKA/lgb_default_model.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgb_default_model, '../../models/ANIKA/lgb_default_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ebead",
   "metadata": {},
   "source": [
    "### exp 4 LightGBM with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "507a7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_tuned_model = LGBMRegressor()\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [150],  \n",
    "    'max_depth': [3, 4, 5],          \n",
    "    'learning_rate': [0.01, 0.1, 0.2]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddbda8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.177881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.051040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.009346\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.029709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.008189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 6879984, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.042669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 8599980, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.028191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5], &#x27;n_estimators&#x27;: [150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5], &#x27;n_estimators&#x27;: [150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5], 'n_estimators': [150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_LGB_tuned = GridSearchCV(lgb_tuned_model, param_grid_lgbm, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_LGB_tuned.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "269b2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "best_params_LGB_tuned = grid_search_LGB_tuned.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params_LGB_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69a16404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 620\n",
      "[LightGBM] [Info] Number of data points in the train set: 8599980, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 382.028191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.2, max_depth=5, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.2, max_depth=5, n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.2, max_depth=5, n_estimators=150)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_tuned_model = LGBMRegressor(**best_params_LGB_tuned)\n",
    "lgb_tuned_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce09aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "train_predictions_lgbm_tuned = lgb_tuned_model.predict(X_train_scaled)\n",
    "test_predictions_lgbm_tuned = lgb_tuned_model.predict(X_test_scaled)\n",
    "val_predictions_lgbm_tuned = lgb_tuned_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b35508f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_lgbm_tuned = mean_squared_error(y_train, train_predictions_lgbm_tuned, squared=False)\n",
    "test_rmse_lgbm_tuned = mean_squared_error(y_test, test_predictions_lgbm_tuned, squared=False)\n",
    "val_rmse_lgbm_tuned = mean_squared_error(y_val, val_predictions_lgbm_tuned, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b19b161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 121.46773009197672\n",
      "Test RMSE: 121.46045650243089\n",
      "Val RMSE: 121.72659048866294\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training RMSE: {train_rmse_lgbm_tuned}\")\n",
    "print(f\"Test RMSE: {test_rmse_lgbm_tuned}\")\n",
    "print(f\"Val RMSE: {val_rmse_lgbm_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0dc0664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/ANIKA/lgb_tuned_model.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgb_tuned_model, '../../models/ANIKA/lgb_tuned_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba10b2b",
   "metadata": {},
   "source": [
    "### exp 5 XGB with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "707a0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_reg = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd9884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_reg = {\n",
    "    'alpha': [0.1, 0.01, 0.001],\n",
    "    'lambda': [1.0, 0.1, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b92574c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;lambda&#x27;: [1.0, 0.1, 0.01]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;lambda&#x27;: [1.0, 0.1, 0.01]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'lambda': [1.0, 0.1, 0.01]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_reg = GridSearchCV(estimator=xgb_model_reg, param_grid=param_grid_reg, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8b8e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = grid_search_reg.best_params_['alpha']\n",
    "best_lambda = grid_search_reg.best_params_['lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a82bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model_reg = XGBRegressor(alpha=best_alpha, reg_lambda=best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b2196c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.001, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.001, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=0.001, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_model_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "306291d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_xgb_reg = best_xgb_model_reg.predict(X_train_scaled)\n",
    "test_predictions_xgb_reg = best_xgb_model_reg.predict(X_test_scaled)\n",
    "val_predictions_xgb_reg = best_xgb_model_reg.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "692a15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_reg = mean_squared_error(y_train, train_predictions_xgb_reg, squared=False)\n",
    "test_rmse_reg = mean_squared_error(y_test, test_predictions_xgb_reg, squared=False)\n",
    "val_rmse_reg = mean_squared_error(y_val, val_predictions_xgb_reg, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "873a92ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 115.89431762695312\n",
      "Test RMSE: 115.97388458251953\n",
      "Val RMSE: 116.27447509765625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training RMSE: {train_rmse_reg}\")\n",
    "print(f\"Test RMSE: {test_rmse_reg}\")\n",
    "print(f\"Val RMSE: {val_rmse_reg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
